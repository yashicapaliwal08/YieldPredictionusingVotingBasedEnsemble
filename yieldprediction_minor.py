# -*- coding: utf-8 -*-
"""yieldprediction_minor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qFpulTYTXwrZr4ubUQfVbkXmD-YeI1XX
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

df=pd.read_csv('crop_production.csv')
df[:5]

"""Data Exploration"""

df.isnull().sum()

data=df.dropna()
print(data.shape)
test=df[~df["Production"].notna()].drop("Production",axis=1)
print(test.shape)

for i in data.columns:
  print("column name:",i)
  print("No. OF column :",len(data[i].unique()))
  print(data[i].unique())

sum_maxp = data["Production"].sum()
data["percent_of_production"] = data["Production"].map(lambda x:(x/sum_maxp)*100)

data[:5]

"""Data Visualization"""

sns.lineplot(x=data["Crop_Year"],y=data["Production"])

plt.figure(figsize=(25,10))
sns.barplot(x=data["State_Name"],y=data["Production"])
plt.xticks(rotation=90)

# sns.jointplot(data["Area"],data["Production"],kind='reg')
sns.barplot(x=data["Season"],y=data["Production"])

data.groupby("Season",axis=0).agg({"Production":np.sum})

data["Crop"].value_counts()[:5]

top_crop_pro = data.groupby("Crop")["Production"].sum().reset_index().sort_values(by='Production',ascending=False)
top_crop_pro[:5]

"""Each type of crops required various area & various season

1.Rice
"""

rice_df = data[data["Crop"]=="Rice"]
print(rice_df.shape)
rice_df[:3]

sns.barplot(x="Season",y="Production",data=rice_df)

plt.figure(figsize=(13,10))
sns.barplot(x="State_Name",y="Production",data=rice_df)
plt.xticks(rotation=90)
plt.show()

top_rice_pro_dis = rice_df.groupby("District_Name")["Production"].sum().reset_index().sort_values(
    by='Production',ascending=False)
top_rice_pro_dis[:5]
sum_max = top_rice_pro_dis["Production"].sum()
top_rice_pro_dis["precent_of_pro"] = top_rice_pro_dis["Production"].map(lambda x:(x/sum_max)*100)
top_rice_pro_dis[:5]

plt.figure(figsize=(18,12))
sns.barplot(x="District_Name",y="Production",data=top_rice_pro_dis)
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize=(15,10))
sns.barplot(x="Crop_Year",y="Production",data=rice_df)
plt.xticks(rotation=45)
plt.show()

# sns.jointplot("Area","Production",data=rice_df,kind="reg")

"""2.Coconut"""

coc_df = data[data["Crop"]=="Coconut "]
print(coc_df.shape)
coc_df[:3]

sns.barplot(x="Season",y="Production",data=coc_df)

plt.figure(figsize=(13,10))
sns.barplot(x="State_Name",y="Production",data=coc_df)
plt.xticks(rotation=90)
plt.show()

top_coc_pro_dis = coc_df.groupby("District_Name")["Production"].sum().reset_index().sort_values(
    by='Production',ascending=False)
top_coc_pro_dis[:5]
sum_max = top_coc_pro_dis["Production"].sum()
top_coc_pro_dis["precent_of_pro"] = top_coc_pro_dis["Production"].map(lambda x:(x/sum_max)*100)
top_coc_pro_dis[:5]

plt.figure(figsize=(18,12))
sns.barplot(x="District_Name",y="Production",data=top_coc_pro_dis)
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize=(15,10))
sns.barplot(x="Crop_Year",y="Production",data=coc_df)
plt.xticks(rotation=45)
plt.show()

# sns.jointplot("Area","Production",data=coc_df,kind="reg")

"""3.Sugarcane"""

sug_df = data[data["Crop"]=="Sugarcane"]
print(sug_df.shape)
sug_df[:3]

sns.barplot(x="Season",y="Production",data=sug_df)

plt.figure(figsize=(13,8))
sns.barplot(x="State_Name",y="Production",data=sug_df)
plt.xticks(rotation=90)
plt.show()

top_sug_pro_dis = sug_df.groupby("District_Name")["Production"].sum().reset_index().sort_values(
    by='Production',ascending=False)
top_sug_pro_dis[:5]
sum_max = top_sug_pro_dis["Production"].sum()
top_sug_pro_dis["precent_of_pro"] = top_sug_pro_dis["Production"].map(lambda x:(x/sum_max)*100)
top_sug_pro_dis[:5]

plt.figure(figsize=(18,8))
sns.barplot(x="District_Name",y="Production",data=top_sug_pro_dis)
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize=(15,10))
sns.barplot(x="Crop_Year",y="Production",data=sug_df)
plt.xticks(rotation=45)
plt.show()

# sns.jointplot("Area","Production",data=sug_df,kind="reg")

"""**Feature Selection**"""

data1 = data.drop(["District_Name","Crop_Year"],axis=1)

data_dum = pd.get_dummies(data1)
data_dum[:5]

"""**Test Train Split**"""

X = data_dum.drop("Production",axis=1)
y = data_dum[["Production"]]
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33, random_state=0)
print("X_train :",X_train.shape)
print("X_test :",X_test.shape)
print("y_train :",y_train.shape)
print("y_test :",y_test.shape)

X_train[:5]

"""**Model 1: Random Forest**"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score,mean_squared_error,matthews_corrcoef
model_rf = RandomForestRegressor(max_depth=2, random_state=0)

model_rf.fit(X_train,y_train.values.ravel())

preds_rf = model_rf.predict(X_test)

r_rf=r2_score(y_test,preds_rf)
rmse_rf=mean_squared_error(y_test,preds_rf,squared=False)
# corr=matthews_corrcoef(y_test,preds)
print("R2 score when we predict using Random Forest is",r_rf)
print("MSE when we predict using Random Forest is",rmse_rf)
# print("Correlation when we predict using Random Forest is",corr)

"""**Model 2:Linear Regression**"""

from sklearn.linear_model import LinearRegression
model_lr=LinearRegression()
model_lr.fit(X_train,y_train)

preds_lr = model_lr.predict(X_test)

r_lr=r2_score(y_test,preds_lr)
rmse_lr=mean_squared_error(y_test,preds_lr,squared=False)
# corr=matthews_corrcoef(y_test,preds)
print("R2 score when we predict using Linear Regression is",r_lr)
print("RMSE when we predict using Linear Regression is",rmse_lr)
# print("Correlation when we predict using Linear Regression is",corr)

"""**Model 3: Extreme Gradient Boosting**"""

from sklearn.ensemble import GradientBoostingRegressor
model_gb=GradientBoostingRegressor()
model_gb.fit(X_train,y_train.values.ravel())
preds_gb=model_gb.predict(X_test)

r_gb=r2_score(y_test,preds_gb)
rmse_gb=mean_squared_error(y_test,preds_gb,squared=False)
# corr=matthews_corrcoef(y_test,preds)
print("R2 score when we predict using Extreme Gradient Boosting is",r_gb)
print("RMSE when we predict using Extreme Gradient Boosting is",rmse_gb)
# print("Correlation when we predict using Extreme Gradient Boosting is",corr)

"""**Model 4:Extra Trees Regressor**"""

from sklearn.ensemble import ExtraTreesRegressor
model_et=ExtraTreesRegressor(n_estimators=100, random_state=0)

model_et.fit(X_train,y_train.values.ravel())

preds_et=model_et.predict(X_test)

r_et=r2_score(y_test,preds_et)
rmse_et=mean_squared_error(y_test,preds_et,squared=False)
# corr=matthews_corrcoef(y_test,preds)
print("R2 score when we predict using Extra Trees Regressor is",r_et)
print("RMSE when we predict using Extra Trees Regressor is",rmse_et)
# print("Correlation when we predict using Extra Trees Regressor is",corr)

"""**Model 4: Decision Tree Regressor**"""

from sklearn.tree import DecisionTreeRegressor
model_dt=DecisionTreeRegressor()
model_dt.fit(X_train,y_train)
preds_dt=model_dt.predict(X_test)

r_dt=r2_score(y_test,preds_dt)
rmse_dt=mean_squared_error(y_test,preds_dt,squared=False)
# corr=matthews_corrcoef(y_test,preds)
print("R2 score when we predict using Decision Trees Regressor is",r_dt)
print("RMSE when we predict using Decision Trees Regressor is",rmse_dt)
# print("Correlation when we predict using Decision Trees Regressor is",corr)

"""**Voting Regression**"""

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import VotingRegressor

estimators_rf_gb=[('rf',model_rf),('egb',model_gb)]

vr_rf_gb=VotingRegressor(estimators_rf_gb)
scores1=cross_val_score(vr_rf_gb,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of random forest and extreme gradient boosting is ',np.round(np.mean(scores1),4))
# scores1=cross_val_score(vr,X_train,y_train.values.ravel(),scoring='neg_root_mean_squared_error',cv=10)
# print('Voting Regressor of random forest and extreme gradient boosting is ',(scores1.mean(), scores1.std()))

estimators_rf_et=[('rf',model_rf),('et',model_et)]
estimators_et_gb=[('et',model_et),('egb',model_gb)]
estimators_dt_gb=[('dt',model_dt),('egb',model_gb)]
estimators_rf_dt=[('rf',model_rf),('dt',model_dt)]
estimators_et_dt=[('et',model_et),('dt',model_dt)]

#rf et
vr_rf_et=VotingRegressor(estimators_rf_et)
scores2=cross_val_score(vr_rf_et,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of random forest and extra trees is ',np.round(np.mean(scores2),4))

#et gb
vr_et_gb=VotingRegressor(estimators_et_gb)
scores3=cross_val_score(vr_et_gb,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of extra trees and extreme gradient boosting is ',np.round(np.mean(scores3),4))

# dt egb
vr_dt_gb=VotingRegressor(estimators_dt_gb)
scores4=cross_val_score(vr_dt_gb,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of decision trees and extreme gradient boosting is ',np.round(np.mean(scores4),4))

#rf dt
vr_rf_dt=VotingRegressor(estimators_rf_dt)
scores5=cross_val_score(vr_rf_dt,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of random forest and decision trees is ',np.round(np.mean(scores5),4))

#et dt
vr_et_dt=VotingRegressor(estimators_et_dt)
scores6=cross_val_score(vr_et_dt,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of extra trees and decision trees is ',np.round(np.mean(scores6),4))

"""RMSE of voting regressors"""

#rf gb
vr_rf_gb.fit(X_train,y_train.values.ravel())
rmse_rf_gb=vr_rf_gb.predict(X_test)
print("RMSE of Random Forest and Extreme Gradient Boosting is",mean_squared_error(y_test,rmse_rf_gb,squared=False))

#rf et
vr_rf_et.fit(X_train,y_train.values.ravel())
rmse_rf_et=vr_rf_et.predict(X_test)
print("RMSE of Random Forest and Extra Trees is",mean_squared_error(y_test,rmse_rf_et,squared=False))

#et gb
vr_et_gb.fit(X_train,y_train.values.ravel())
rmse_et_gb=vr_et_gb.predict(X_test)
print("RMSE of Extra Trees and Extreme Gradient Boosting is",mean_squared_error(y_test,rmse_et_gb,squared=False))

#dt gb
vr_dt_gb.fit(X_train,y_train.values.ravel())
rmse_dt_gb=vr_dt_gb.predict(X_test)
print("RMSE of decision trees and Extreme Gradient Boosting is",mean_squared_error(y_test,rmse_dt_gb,squared=False))

#rf dt
vr_rf_dt.fit(X_train,y_train.values.ravel())
rmse_rf_dt=vr_rf_dt.predict(X_test)
print("RMSE of Random Forest and decision trees is",mean_squared_error(y_test,rmse_rf_dt,squared=False))

#et dt
vr_et_dt.fit(X_train,y_train.values.ravel())
rmse_et_dt=vr_et_dt.predict(X_test)
print("RMSE of Extra Trees and Decision Trees is",mean_squared_error(y_test,rmse_et_dt,squared=False))

"""Voting regressor of random forest ,extreme boosting gradient and extra trees
including rmse and r2 score
"""

estimators_rf_gb_et=[('rf',model_rf),('egb',model_gb),('et',model_et)]
vr_rf_gb_et=VotingRegressor(estimators_rf_gb_et)
scores_rf_gb_et=cross_val_score(vr_rf_gb_et,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of random forest ,extreme gradient boosting and extra trees is ',np.round(np.mean(scores_rf_gb_et),4))
vr_rf_gb_et.fit(X_train,y_train.values.ravel())
rmse_rf_gb_et=vr_rf_gb_et.predict(X_test)
print("RMSE of Random Forest, Extreme Gradient Boosting and Extra Trees is",mean_squared_error(y_test,rmse_rf_gb_et,squared=False))

estimators_rf_et_dt=[('rf',model_rf),('et',model_et),('dt',model_dt)]
vr_rf_et_dt=VotingRegressor(estimators_rf_et_dt)
scores_rf_et_dt=cross_val_score(vr_rf_et_dt,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of random forest ,extra trees and decision trees is ',np.round(np.mean(scores_rf_et_dt),4))
vr_rf_et_dt.fit(X_train,y_train.values.ravel())
rmse_rf_et_dt=vr_rf_et_dt.predict(X_test)
print("RMSE of Random Forest, extra trees and decision trees is",mean_squared_error(y_test,rmse_rf_et_dt,squared=False))

estimators_gb_et_dt=[('egb',model_gb),('et',model_et),('dt',model_dt)]
vr_gb_et_dt=VotingRegressor(estimators_gb_et_dt)
scores_gb_et_dt=cross_val_score(vr_gb_et_dt,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of extreme gradient boosting ,extra trees and decision trees is ',np.round(np.mean(scores_gb_et_dt),4))
vr_gb_et_dt.fit(X_train,y_train.values.ravel())
rmse_gb_et_dt=vr_gb_et_dt.predict(X_test)
print("RMSE of extreme boosting gradient, extra trees and decision trees is",mean_squared_error(y_test,rmse_gb_et_dt,squared=False))

"""Mean Absolute Errors-"""

from sklearn.metrics import mean_absolute_error
mae_rf=mean_absolute_error(y_test, preds_rf)
mae_gb=mean_absolute_error(y_test, preds_gb)
mae_et=mean_absolute_error(y_test, preds_et)
mae_dt=mean_absolute_error(y_test, preds_dt)
mae_lr=mean_absolute_error(y_test,preds_lr)
mae_rf_gb=mean_absolute_error(y_test,rmse_rf_gb)
mae_rf_et=mean_absolute_error(y_test, rmse_rf_et)
mae_et_gb=mean_absolute_error(y_test,rmse_rf_gb)
mae_dt_gb=mean_absolute_error(y_test, rmse_dt_gb)
mae_rf_dt=mean_absolute_error(y_test,rmse_rf_dt)
mae_et_dt=mean_absolute_error(y_test,rmse_et_dt)
print("MAE of random forest is",mae_rf)
print("MAE of extreme gradient boosting is",mae_gb)
print("MAE of extra trees is",mae_et)
print("MAE of decision trees is",mae_dt)
print("MAE of linear regression is ",mae_lr)
print("MAE of random forest and extreme gradient boosting is",mae_rf_gb)
print("MAE of random forest and extra trees is",mae_rf_et)
print("MAE of extra trees and extreme gradient boosting is",mae_et_gb)
print("MAE of decision trees and extreme gradient boosting is",mae_dt_gb)
print("MAE of random forest and decision trees is",mae_rf_dt)
print("MAE of extra trees and decision trees is",mae_et_dt)
print("MAE of Random Forest, Extreme Gradient Boosting and Extra Trees is",mean_absolute_error(y_test,rmse_rf_gb_et))
print("MAE of Random Forest, extra trees and decision trees is",mean_absolute_error(y_test,rmse_rf_et_dt))
print("MAE of extreme gradient boosting, extra trees and decision trees is",mean_absolute_error(y_test,rmse_gb_et_dt))

"""Voting regressor in terms of linear regression"""

estimators_et_lr=[('et',model_et),('lr',model_lr)]
vr_et_lr=VotingRegressor(estimators_et_lr)
scores_et_lr=cross_val_score(vr_et_lr,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of extra trees and linear regression is ',np.round(np.mean(scores_et_lr),4))
vr_et_lr.fit(X_train,y_train.values.ravel())
rmse_et_lr=vr_et_lr.predict(X_test)
print("RMSE of extra trees and linear regression is",mean_squared_error(y_test,rmse_et_lr,squared=False))
print("MAE of extra trees and linear regression is",mean_absolute_error(y_test,rmse_et_lr))

#gb lr
estimators_gb_lr=[('egb',model_gb),('lr',model_lr)]
vr_gb_lr=VotingRegressor(estimators_gb_lr)
scores_gb_lr=cross_val_score(vr_gb_lr,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of extreme gradient boosting and linear regression is ',np.round(np.mean(scores_gb_lr),4))
vr_gb_lr.fit(X_train,y_train.values.ravel())
rmse_gb_lr=vr_gb_lr.predict(X_test)
print("RMSE of extreme gradient boosting and linear regression is",mean_squared_error(y_test,rmse_gb_lr,squared=False))
print("MAE of extreme gradient boosting and linear regression is",mean_absolute_error(y_test,rmse_gb_lr))

#dt lr
estimators_dt_lr=[('dt',model_dt),('lr',model_lr)]
vr_dt_lr=VotingRegressor(estimators_dt_lr)
scores_dt_lr=cross_val_score(vr_dt_lr,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of decision trees and linear regression is ',np.round(np.mean(scores_dt_lr),4))
vr_dt_lr.fit(X_train,y_train.values.ravel())
rmse_dt_lr=vr_dt_lr.predict(X_test)
print("RMSE of decision trees and linear regression is",mean_squared_error(y_test,rmse_dt_lr,squared=False))
print("MAE of decision trees and linear regression is",mean_absolute_error(y_test,rmse_dt_lr))

#gb et lr
estimators_gb_et_lr=[('egb',model_gb),('et',model_et),('lr',model_lr)]
vr_gb_et_lr=VotingRegressor(estimators_gb_et_lr)
scores_gb_et_lr=cross_val_score(vr_gb_et_lr,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of extreme gradient boosting ,extra trees and linear regression is ',np.round(np.mean(scores_gb_et_lr),4))
vr_gb_et_lr.fit(X_train,y_train.values.ravel())
rmse_gb_et_lr=vr_gb_et_lr.predict(X_test)
print("RMSE of extreme boosting gradient, extra trees and linear regression is",mean_squared_error(y_test,rmse_gb_et_lr,squared=False))
print("MAE of extreme boosting gradient, extra trees and linear regression is",mean_absolute_error(y_test,rmse_gb_et_lr))

#et dt lr
estimators_et_dt_lr=[('dt',model_dt),('et',model_et),('lr',model_lr)]
vr_dt_et_lr=VotingRegressor(estimators_et_dt_lr)
scores_dt_et_lr=cross_val_score(vr_dt_et_lr,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of decision trees ,extra trees and linear regression is ',np.round(np.mean(scores_dt_et_lr),4))
vr_dt_et_lr.fit(X_train,y_train.values.ravel())
rmse_dt_et_lr=vr_dt_et_lr.predict(X_test)
print("RMSE of decision trees, extra trees and linear regression is",mean_squared_error(y_test,rmse_dt_et_lr,squared=False))
print("MAE of decision trees, extra trees and linear regression is",mean_absolute_error(y_test,rmse_dt_et_lr))

#egb dt lr
estimators_gb_dt_lr=[('egb',model_gb),('dt',model_dt),('lr',model_lr)]
vr_gb_dt_lr=VotingRegressor(estimators_gb_dt_lr)
scores_gb_dt_lr=cross_val_score(vr_gb_dt_lr,X_train,y_train.values.ravel(),scoring='r2',cv=10)
print('Voting Regressor of extreme gradient boosting, decision trees and linear regression is ',np.round(np.mean(scores_gb_dt_lr),4))
vr_gb_dt_lr.fit(X_train,y_train.values.ravel())
rmse_gb_dt_lr=vr_gb_dt_lr.predict(X_test)
print("RMSE of extreme boosting gradient,decision  trees and linear regression is",mean_squared_error(y_test,rmse_gb_dt_lr,squared=False))
print("MAE of extreme boosting gradient, decision trees and linear regression is",mean_absolute_error(y_test,rmse_gb_dt_lr))

"""**Stacking Regressor**"""

from sklearn.ensemble import StackingRegressor
estimators=[('dt',model_dt),('egb',model_gb),('et',model_et)]

reg=StackingRegressor(estimators=estimators,final_estimator=model_lr)
reg.fit(X_train,y_train.values.ravel())

reg.get_params()

predictions=reg.predict(X_test)

predictions[0:5]

reg.score(X_test,y_test)

print("RMSE of stacking based regression is",mean_squared_error(y_test,predictions,squared=False))
print("MAE of stacking based regression is",mean_absolute_error(y_test,predictions))

"""r2,rmse,mae score of training data"""

preds_train_rf=model_rf.predict(X_train)
print("R2 score of training data is",r2_score(y_train,preds_train_rf))
print("RMSE of training data random forest is",mean_squared_error(y_train,preds_train_rf,squared=False))
print("MAE of training data random Forest is",mean_absolute_error(y_train,preds_train_rf))

preds_train_lr=model_lr.predict(X_train)
print("R2 score of training data is",r2_score(y_train,preds_train_lr))
print("RMSE of training data linear Regression is",mean_squared_error(y_train,preds_train_lr,squared=False))
print("MAE of training data linear regression is",mean_absolute_error(y_train,preds_train_lr))

preds_train_gb=model_gb.predict(X_train)
print("R2 score of training data is",r2_score(y_train,preds_train_gb))
print("RMSE of training data extreme gradient boosting is",mean_squared_error(y_train,preds_train_gb,squared=False))
print("MAE of training data extreme gradient boosting is",mean_absolute_error(y_train,preds_train_gb))

preds_train_et=model_et.predict(X_train)
print("R2 score of training data is",r2_score(y_train,preds_train_et))
print("RMSE of training data extra trees is",mean_squared_error(y_train,preds_train_et,squared=False))
print("MAE of training data extra trees is",mean_absolute_error(y_train,preds_train_et))

preds_train_dt=model_dt.predict(X_train)
print("R2 score of training data is",r2_score(y_train,preds_train_dt))
print("RMSE of training data decision trees is",mean_squared_error(y_train,preds_train_dt,squared=False))
print("MAE of training data decision trees is",mean_absolute_error(y_train,preds_train_dt))

"""Cross val score of models-"""

import math
print("Cross val r2 score of random forest is",cross_val_score(model_rf,X_train,y_train.values.ravel(),scoring='r2',cv=10))
print("Cross val rmse score of random forest is",math.sqrt(cross_val_score(model_rf,X_train,y_train.values.ravel(),scoring='mean_squared_error',cv=10)))
print("Cross val mae score of random forest is",cross_val_score(model_rf,X_train,y_train.values.ravel(),scoring='mean_absolute_error',cv=10))

print("Cross val r2 score of linear regression is",cross_val_score(model_lr,X_train,y_train.values.ravel(),scoring='r2',cv=10))
print("Cross val rmse score of linear regression is",math.sqrt(cross_val_score(model_lr,X_train,y_train.values.ravel(),scoring='mean_squared_error',cv=10)))
print("Cross val mae score of linear regression is",cross_val_score(model_lr,X_train,y_train.values.ravel(),scoring='mean_absolute_error',cv=10))

print("Cross val r2 score of decision trees is",cross_val_score(model_dt,X_train,y_train.values.ravel(),scoring='r2',cv=10))
print("Cross val rmse score of decision trees is",math.sqrt(cross_val_score(model_dt,X_train,y_train.values.ravel(),scoring='mean_squared_error',cv=10)))
print("Cross val mae score of decision trees is",cross_val_score(model_dt,X_train,y_train.values.ravel(),scoring='mean_absolute_error',cv=10))

print("Cross val r2 score of extra trees is",cross_val_score(model_et,X_train,y_train.values.ravel(),scoring='r2',cv=10))
print("Cross val rmse score of extra trees is",math.sqrt(cross_val_score(model_et,X_train,y_train.values.ravel(),scoring='mean_squared_error',cv=10)))
print("Cross val mae score of extra trees is",cross_val_score(model_et,X_train,y_train.values.ravel(),scoring='mean_absolute_error',cv=10))

print("Cross val r2 score of extreme gradient boosting is",cross_val_score(model_gb,X_train,y_train.values.ravel(),scoring='r2',cv=10))
print("Cross val rmse score of extreme gradient boosting is",math.sqrt(cross_val_score(model_gb,X_train,y_train.values.ravel(),scoring='mean_squared_error',cv=10)))
print("Cross val mae score of extreme gradient boosting is",cross_val_score(model_gb,X_train,y_train.values.ravel(),scoring='mean_absolute_error',cv=10))

